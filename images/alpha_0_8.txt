/home/snowkylin/anaconda2/envs/tensorflow/bin/python /home/snowkylin/桌面/rnn_vae/train.py
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: 
name: GeForce GTX 1060 6GB
major: 6 minor: 1 memoryClockRate (GHz) 1.8095
pciBusID 0000:01:00.0
Total memory: 5.96GiB
Free memory: 5.52GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0)
epoch 0
batches 0, loss 479.206 (re: 590.406, kl: 34.4053)
batches 100, loss 163.244 (re: 202.767, kl: 5.1507)
batches 200, loss 163.488 (re: 203.463, kl: 3.58757)
batches 300, loss 157.07 (re: 194.287, kl: 8.2)
batches 400, loss 149.878 (re: 185.419, kl: 7.71398)
batches 500, loss 144.932 (re: 177.263, kl: 15.6093)
batches 600, loss 131.392 (re: 160.118, kl: 16.4844)
batches 700, loss 119.356 (re: 145.273, kl: 15.6857)
batches 800, loss 112.626 (re: 136.261, kl: 18.0871)
batches 900, loss 101.392 (re: 122.718, kl: 16.0871)
epoch 1
batches 0, loss 90.3255 (re: 109.234, kl: 14.6936)
batches 100, loss 89.8712 (re: 108.707, kl: 14.5275)
batches 200, loss 83.9274 (re: 101.305, kl: 14.4177)
batches 300, loss 83.2492 (re: 100.707, kl: 13.4158)
batches 400, loss 82.1394 (re: 99.3331, kl: 13.3644)
batches 500, loss 84.5057 (re: 102.229, kl: 13.6139)
batches 600, loss 77.5446 (re: 93.5962, kl: 13.3379)
batches 700, loss 76.4728 (re: 92.3824, kl: 12.8345)
batches 800, loss 72.6571 (re: 87.7933, kl: 12.1123)
batches 900, loss 70.268 (re: 84.9438, kl: 11.5646)
epoch 2
batches 0, loss 69.1889 (re: 83.8214, kl: 10.6587)
batches 100, loss 70.1058 (re: 84.8166, kl: 11.2629)
batches 200, loss 66.6448 (re: 80.7556, kl: 10.2015)
batches 300, loss 69.8798 (re: 84.7212, kl: 10.5142)
batches 400, loss 62.5447 (re: 75.7863, kl: 9.57822)
batches 500, loss 64.9875 (re: 79.0088, kl: 8.90224)
batches 600, loss 63.8823 (re: 77.6832, kl: 8.6788)
batches 700, loss 62.666 (re: 76.1479, kl: 8.73812)
batches 800, loss 57.817 (re: 70.0761, kl: 8.78085)
batches 900, loss 60.6409 (re: 73.6739, kl: 8.50903)
epoch 3
batches 0, loss 58.0405 (re: 70.5704, kl: 7.92091)
batches 100, loss 61.8675 (re: 75.2307, kl: 8.41457)
batches 200, loss 60.1303 (re: 73.2699, kl: 7.57176)
batches 300, loss 58.4535 (re: 71.2026, kl: 7.45735)
batches 400, loss 59.0084 (re: 71.8642, kl: 7.58539)
batches 500, loss 61.0348 (re: 74.4004, kl: 7.57238)
batches 600, loss 57.5846 (re: 70.1309, kl: 7.39956)
batches 700, loss 57.1599 (re: 69.6969, kl: 7.012)
batches 800, loss 56.2533 (re: 68.6079, kl: 6.8348)
batches 900, loss 58.3661 (re: 71.2541, kl: 6.81411)
epoch 4
batches 0, loss 58.1577 (re: 70.9826, kl: 6.85776)
batches 100, loss 57.2575 (re: 69.9626, kl: 6.4371)
batches 200, loss 56.913 (re: 69.5358, kl: 6.42178)
batches 300, loss 53.485 (re: 65.2411, kl: 6.46056)
batches 400, loss 55.9575 (re: 68.3604, kl: 6.34581)
batches 500, loss 56.7447 (re: 69.2453, kl: 6.74226)
batches 600, loss 55.5904 (re: 67.9534, kl: 6.13836)
batches 700, loss 54.0017 (re: 66.0208, kl: 5.92537)
batches 800, loss 53.3756 (re: 65.2633, kl: 5.82497)
batches 900, loss 52.6622 (re: 64.4545, kl: 5.49275)
epoch 5
batches 0, loss 54.6169 (re: 66.7835, kl: 5.95031)
batches 100, loss 53.6208 (re: 65.6187, kl: 5.62924)
batches 200, loss 52.3177 (re: 64.0113, kl: 5.54349)
batches 300, loss 51.964 (re: 63.6403, kl: 5.25871)
batches 400, loss 53.5147 (re: 65.4377, kl: 5.82245)
batches 500, loss 50.0257 (re: 61.2657, kl: 5.0659)
batches 600, loss 48.5133 (re: 59.4153, kl: 4.90523)
batches 700, loss 52.898 (re: 64.7578, kl: 5.45877)
batches 800, loss 52.7874 (re: 64.695, kl: 5.1571)
batches 900, loss 51.418 (re: 63.0067, kl: 5.06299)
epoch 6
batches 0, loss 53.3393 (re: 65.4202, kl: 5.0159)
batches 100, loss 52.8555 (re: 64.8642, kl: 4.82077)
batches 200, loss 51.7701 (re: 63.4446, kl: 5.07216)
batches 300, loss 49.9109 (re: 61.2441, kl: 4.57796)
batches 400, loss 51.3961 (re: 63.0471, kl: 4.79186)
batches 500, loss 50.7384 (re: 62.2263, kl: 4.78683)
batches 600, loss 50.4399 (re: 61.9179, kl: 4.52782)
batches 700, loss 50.8861 (re: 62.4549, kl: 4.61084)
batches 800, loss 51.1659 (re: 62.8017, kl: 4.62299)
batches 900, loss 50.6113 (re: 62.1099, kl: 4.61691)
epoch 7
batches 0, loss 46.1587 (re: 56.7214, kl: 3.90823)
batches 100, loss 50.0729 (re: 61.5074, kl: 4.33522)
batches 200, loss 49.889 (re: 61.2059, kl: 4.62156)
batches 300, loss 49.6384 (re: 61.0742, kl: 3.89484)
batches 400, loss 50.8422 (re: 62.4762, kl: 4.30646)
batches 500, loss 46.6593 (re: 57.3173, kl: 4.02744)
batches 600, loss 49.2315 (re: 60.5048, kl: 4.13849)
batches 700, loss 48.819 (re: 59.9821, kl: 4.16669)
batches 800, loss 47.1063 (re: 57.9518, kl: 3.72425)
batches 900, loss 48.6604 (re: 59.7761, kl: 4.19797)
epoch 8
batches 0, loss 47.9726 (re: 59.0093, kl: 3.82576)
batches 100, loss 51.3211 (re: 63.1432, kl: 4.03264)
batches 200, loss 49.6434 (re: 61.0217, kl: 4.13045)
batches 300, loss 46.3247 (re: 56.9468, kl: 3.83598)
batches 400, loss 45.7063 (re: 56.1703, kl: 3.85033)
batches 500, loss 48.8384 (re: 60.0367, kl: 4.04552)
batches 600, loss 47.3665 (re: 58.2237, kl: 3.93759)
batches 700, loss 48.8458 (re: 60.0397, kl: 4.07022)
batches 800, loss 48.8732 (re: 60.1812, kl: 3.64115)
batches 900, loss 48.4045 (re: 59.5791, kl: 3.70596)
epoch 9
batches 0, loss 49.1646 (re: 60.4884, kl: 3.86929)
batches 100, loss 46.9455 (re: 57.7803, kl: 3.60611)
batches 200, loss 46.7228 (re: 57.5428, kl: 3.44268)
batches 300, loss 49.9845 (re: 61.5093, kl: 3.88531)
batches 400, loss 44.6497 (re: 54.9766, kl: 3.34207)
batches 500, loss 47.4711 (re: 58.4476, kl: 3.56497)
batches 600, loss 46.5741 (re: 57.3104, kl: 3.62912)
batches 700, loss 45.6041 (re: 56.1859, kl: 3.27668)
batches 800, loss 45.5821 (re: 56.1439, kl: 3.33508)
batches 900, loss 49.4098 (re: 60.8786, kl: 3.53479)
epoch 10
batches 0, loss 47.8495 (re: 58.9683, kl: 3.374)
batches 100, loss 46.5687 (re: 57.3592, kl: 3.40695)
batches 200, loss 46.1724 (re: 56.8889, kl: 3.30655)
batches 300, loss 47.0567 (re: 57.9854, kl: 3.34205)
batches 400, loss 46.5397 (re: 57.338, kl: 3.34674)
batches 500, loss 46.8007 (re: 57.6588, kl: 3.36799)
batches 600, loss 44.5845 (re: 54.9377, kl: 3.17147)
batches 700, loss 47.591 (re: 58.6736, kl: 3.26099)
batches 800, loss 49.5184 (re: 61.0413, kl: 3.42704)
batches 900, loss 48.6729 (re: 59.9952, kl: 3.38375)
epoch 11
batches 0, loss 45.0968 (re: 55.6127, kl: 3.03322)
batches 100, loss 45.7208 (re: 56.3329, kl: 3.27239)
batches 200, loss 46.2853 (re: 57.0799, kl: 3.10711)
batches 300, loss 43.7582 (re: 53.9165, kl: 3.12479)
batches 400, loss 45.5735 (re: 56.228, kl: 2.95513)
batches 500, loss 45.7561 (re: 56.4582, kl: 2.94768)
batches 600, loss 44.4706 (re: 54.8507, kl: 2.95001)
batches 700, loss 47.2268 (re: 58.2708, kl: 3.0508)
batches 800, loss 47.5651 (re: 58.6685, kl: 3.15163)
batches 900, loss 44.2926 (re: 54.617, kl: 2.9954)
epoch 12
batches 0, loss 44.568 (re: 54.9461, kl: 3.05529)
batches 100, loss 45.4935 (re: 56.1316, kl: 2.94075)
batches 200, loss 45.2894 (re: 55.8372, kl: 3.0985)
batches 300, loss 43.7316 (re: 53.976, kl: 2.75416)
batches 400, loss 45.7542 (re: 56.4836, kl: 2.83656)
batches 500, loss 46.3353 (re: 57.1745, kl: 2.97871)
batches 600, loss 45.5559 (re: 56.2428, kl: 2.80847)
batches 700, loss 46.0739 (re: 56.8588, kl: 2.93415)
batches 800, loss 45.302 (re: 55.9124, kl: 2.86046)
batches 900, loss 45.0211 (re: 55.5575, kl: 2.8753)
epoch 13
batches 0, loss 45.9908 (re: 56.7803, kl: 2.8328)
batches 100, loss 45.2218 (re: 55.8543, kl: 2.69203)
batches 200, loss 46.171 (re: 57.0187, kl: 2.78023)
batches 300, loss 47.1691 (re: 58.2459, kl: 2.86185)
batches 400, loss 46.4528 (re: 57.3344, kl: 2.92656)
batches 500, loss 45.5353 (re: 56.2474, kl: 2.68698)
batches 600, loss 44.9468 (re: 55.4915, kl: 2.76781)
batches 700, loss 46.0078 (re: 56.8732, kl: 2.54649)
batches 800, loss 46.7156 (re: 57.6826, kl: 2.84769)
batches 900, loss 44.4238 (re: 54.861, kl: 2.67496)
epoch 14
batches 0, loss 45.604 (re: 56.3111, kl: 2.77567)
batches 100, loss 42.111 (re: 51.979, kl: 2.63886)
batches 200, loss 43.5268 (re: 53.7461, kl: 2.64973)
batches 300, loss 44.1647 (re: 54.5497, kl: 2.62468)
batches 400, loss 45.3217 (re: 56.0081, kl: 2.57604)
batches 500, loss 46.2723 (re: 57.1611, kl: 2.71731)
batches 600, loss 44.1469 (re: 54.5188, kl: 2.65941)
batches 700, loss 44.8892 (re: 55.4697, kl: 2.5674)
batches 800, loss 44.3434 (re: 54.7625, kl: 2.66683)
batches 900, loss 44.1805 (re: 54.5835, kl: 2.56857)
epoch 15
batches 0, loss 43.8359 (re: 54.1358, kl: 2.63625)
batches 100, loss 43.4539 (re: 53.6882, kl: 2.51661)
batches 200, loss 44.651 (re: 55.1864, kl: 2.50937)
batches 300, loss 45.1087 (re: 55.7449, kl: 2.56415)
batches 400, loss 42.7125 (re: 52.7758, kl: 2.45912)
batches 500, loss 44.7125 (re: 55.2584, kl: 2.52888)
batches 600, loss 44.3464 (re: 54.7944, kl: 2.55435)
batches 700, loss 45.1401 (re: 55.8029, kl: 2.48898)
batches 800, loss 43.9813 (re: 54.403, kl: 2.29466)
batches 900, loss 44.39 (re: 54.8865, kl: 2.40382)
epoch 16
batches 0, loss 44.4627 (re: 54.9708, kl: 2.43048)
batches 100, loss 45.9563 (re: 56.8243, kl: 2.48399)
batches 200, loss 44.4925 (re: 55.0048, kl: 2.4431)
batches 300, loss 43.5132 (re: 53.8237, kl: 2.27103)
batches 400, loss 43.2716 (re: 53.4857, kl: 2.41503)
batches 500, loss 42.9995 (re: 53.1541, kl: 2.38105)
batches 600, loss 43.7161 (re: 54.023, kl: 2.48809)
batches 700, loss 44.4238 (re: 54.9549, kl: 2.29958)
batches 800, loss 46.8178 (re: 57.9366, kl: 2.34245)
batches 900, loss 43.6628 (re: 54.012, kl: 2.26615)
epoch 17
batches 0, loss 43.9417 (re: 54.3435, kl: 2.33431)
batches 100, loss 45.7352 (re: 56.5449, kl: 2.49634)
batches 200, loss 43.3355 (re: 53.6205, kl: 2.19586)
batches 300, loss 45.1148 (re: 55.8079, kl: 2.34269)
batches 400, loss 44.4372 (re: 54.9632, kl: 2.33315)
batches 500, loss 43.1015 (re: 53.312, kl: 2.25967)
batches 600, loss 46.0595 (re: 56.9545, kl: 2.47938)
batches 700, loss 42.4873 (re: 52.5723, kl: 2.14736)
batches 800, loss 43.0096 (re: 53.1672, kl: 2.37923)
batches 900, loss 42.762 (re: 52.9077, kl: 2.17931)
epoch 18
batches 0, loss 43.4647 (re: 53.7533, kl: 2.31022)
batches 100, loss 43.1993 (re: 53.4595, kl: 2.15848)
batches 200, loss 42.712 (re: 52.8289, kl: 2.24426)
batches 300, loss 44.2777 (re: 54.8031, kl: 2.17636)
batches 400, loss 43.8771 (re: 54.283, kl: 2.25365)
batches 500, loss 43.903 (re: 54.3189, kl: 2.23958)
batches 600, loss 44.3864 (re: 54.8984, kl: 2.33835)
batches 700, loss 44.1595 (re: 54.6253, kl: 2.29636)
batches 800, loss 44.579 (re: 55.1767, kl: 2.1882)
batches 900, loss 42.5198 (re: 52.6089, kl: 2.16331)
epoch 19
batches 0, loss 43.2866 (re: 53.5416, kl: 2.26678)
batches 100, loss 42.269 (re: 52.3255, kl: 2.04289)
batches 200, loss 45.7697 (re: 56.6317, kl: 2.32171)
batches 300, loss 40.6704 (re: 50.3294, kl: 2.03442)
batches 400, loss 42.4445 (re: 52.5633, kl: 1.96952)
batches 500, loss 43.6778 (re: 54.0446, kl: 2.21053)
batches 600, loss 42.7885 (re: 52.9558, kl: 2.11915)
batches 700, loss 45.2444 (re: 55.9859, kl: 2.27813)
batches 800, loss 43.0449 (re: 53.2846, kl: 2.08582)
batches 900, loss 43.9456 (re: 54.4089, kl: 2.09203)

Process finished with exit code 0

