/home/snowkylin/anaconda2/envs/tensorflow/bin/python /home/snowkylin/桌面/rnn_vae/train.py
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: 
name: GeForce GTX 1060 6GB
major: 6 minor: 1 memoryClockRate (GHz) 1.8095
pciBusID 0000:01:00.0
Total memory: 5.96GiB
Free memory: 5.37GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0)
epoch 0
batches 0, loss 293.761 (re: 580.54, kl: 6.98257)
batches 100, loss 103.022 (re: 202.835, kl: 3.20874)
batches 200, loss 102.58 (re: 203.878, kl: 1.2824)
batches 300, loss 103.921 (re: 207.746, kl: 0.0955168)
batches 400, loss 102.577 (re: 205.093, kl: 0.0602262)
batches 500, loss 106.395 (re: 212.725, kl: 0.0652545)
batches 600, loss 103.952 (re: 207.768, kl: 0.136186)
batches 700, loss 99.2806 (re: 195.749, kl: 2.81275)
batches 800, loss 95.9928 (re: 190.87, kl: 1.11601)
batches 900, loss 89.044 (re: 176.378, kl: 1.70993)
epoch 1
batches 0, loss 85.3965 (re: 169.665, kl: 1.12841)
batches 100, loss 82.591 (re: 164.121, kl: 1.061)
batches 200, loss 79.0885 (re: 156.749, kl: 1.42763)
batches 300, loss 73.3799 (re: 144.844, kl: 1.9154)
batches 400, loss 71.9568 (re: 142.009, kl: 1.90474)
batches 500, loss 71.681 (re: 141.146, kl: 2.21575)
batches 600, loss 69.2646 (re: 136.574, kl: 1.95521)
batches 700, loss 68.9691 (re: 135.879, kl: 2.05895)
batches 800, loss 63.0346 (re: 123.601, kl: 2.46786)
batches 900, loss 61.2391 (re: 119.845, kl: 2.63338)
epoch 2
batches 0, loss 60.9461 (re: 119.01, kl: 2.88243)
batches 100, loss 60.4791 (re: 118.309, kl: 2.6495)
batches 200, loss 59.1405 (re: 116.045, kl: 2.23559)
batches 300, loss 60.4638 (re: 118.301, kl: 2.62631)
batches 400, loss 60.8941 (re: 119.225, kl: 2.56341)
batches 500, loss 58.1296 (re: 113.939, kl: 2.32043)
batches 600, loss 56.3251 (re: 110.113, kl: 2.5374)
batches 700, loss 54.8593 (re: 107.338, kl: 2.38091)
batches 800, loss 57.0793 (re: 111.348, kl: 2.81065)
batches 900, loss 56.249 (re: 109.916, kl: 2.58201)
epoch 3
batches 0, loss 50.3511 (re: 98.3531, kl: 2.34916)
batches 100, loss 55.6952 (re: 108.794, kl: 2.59648)
batches 200, loss 51.874 (re: 101.185, kl: 2.56283)
batches 300, loss 51.0476 (re: 99.6359, kl: 2.45938)
batches 400, loss 49.5068 (re: 96.5107, kl: 2.503)
batches 500, loss 49.4903 (re: 96.5077, kl: 2.47289)
batches 600, loss 45.5554 (re: 88.6087, kl: 2.50219)
batches 700, loss 50.7343 (re: 98.9358, kl: 2.53281)
batches 800, loss 50.2081 (re: 98.0342, kl: 2.3819)
batches 900, loss 48.3164 (re: 94.1667, kl: 2.46612)
epoch 4
batches 0, loss 46.9789 (re: 91.7152, kl: 2.24269)
batches 100, loss 48.5928 (re: 94.8895, kl: 2.29614)
batches 200, loss 45.44 (re: 88.5552, kl: 2.32468)
batches 300, loss 44.4018 (re: 86.4614, kl: 2.3422)
batches 400, loss 46.8167 (re: 91.5064, kl: 2.12704)
batches 500, loss 44.3435 (re: 86.3652, kl: 2.32185)
batches 600, loss 45.038 (re: 87.8421, kl: 2.23376)
batches 700, loss 43.7417 (re: 85.2932, kl: 2.19026)
batches 800, loss 45.0735 (re: 87.9275, kl: 2.21962)
batches 900, loss 45.3302 (re: 88.3861, kl: 2.27428)
epoch 5
batches 0, loss 41.848 (re: 81.5096, kl: 2.18641)
batches 100, loss 45.1417 (re: 88.0335, kl: 2.24993)
batches 200, loss 41.4868 (re: 80.9109, kl: 2.06258)
batches 300, loss 42.5051 (re: 82.9037, kl: 2.1066)
batches 400, loss 40.8201 (re: 79.7116, kl: 1.92857)
batches 500, loss 42.7297 (re: 83.3518, kl: 2.10754)
batches 600, loss 40.3919 (re: 78.8253, kl: 1.95848)
batches 700, loss 42.5285 (re: 83.0983, kl: 1.95866)
batches 800, loss 40.0742 (re: 78.2116, kl: 1.93676)
batches 900, loss 40.9316 (re: 79.9783, kl: 1.88494)
epoch 6
batches 0, loss 39.8431 (re: 77.7064, kl: 1.97981)
batches 100, loss 41.5498 (re: 81.1008, kl: 1.99888)
batches 200, loss 38.261 (re: 74.7644, kl: 1.75766)
batches 300, loss 39.8549 (re: 77.7638, kl: 1.94597)
batches 400, loss 39.9824 (re: 78.2014, kl: 1.76335)
batches 500, loss 39.0852 (re: 76.391, kl: 1.77932)
batches 600, loss 37.5743 (re: 73.4635, kl: 1.68501)
batches 700, loss 38.601 (re: 75.488, kl: 1.71402)
batches 800, loss 37.9136 (re: 74.1022, kl: 1.72491)
batches 900, loss 39.3553 (re: 76.9535, kl: 1.75704)
epoch 7
batches 0, loss 38.7376 (re: 75.7902, kl: 1.68511)
batches 100, loss 36.6233 (re: 71.6721, kl: 1.57452)
batches 200, loss 38.7143 (re: 75.705, kl: 1.72366)
batches 300, loss 37.3977 (re: 73.1738, kl: 1.62148)
batches 400, loss 38.2888 (re: 74.8702, kl: 1.70726)
batches 500, loss 38.2786 (re: 74.9145, kl: 1.64273)
batches 600, loss 38.3441 (re: 74.9848, kl: 1.70348)
batches 700, loss 37.1449 (re: 72.5068, kl: 1.78297)
batches 800, loss 37.5673 (re: 73.5793, kl: 1.55528)
batches 900, loss 33.7366 (re: 66.0211, kl: 1.45212)
epoch 8
batches 0, loss 37.2269 (re: 72.9751, kl: 1.47878)
batches 100, loss 36.3829 (re: 71.2853, kl: 1.48058)
batches 200, loss 37.9281 (re: 74.3145, kl: 1.54169)
batches 300, loss 34.8508 (re: 68.2909, kl: 1.41061)
batches 400, loss 34.7221 (re: 68.0218, kl: 1.42236)
batches 500, loss 34.4982 (re: 67.6453, kl: 1.35115)
batches 600, loss 36.761 (re: 72.0365, kl: 1.48547)
batches 700, loss 34.8473 (re: 68.2605, kl: 1.43411)
batches 800, loss 35.1359 (re: 68.8673, kl: 1.40451)
batches 900, loss 35.2321 (re: 69.1316, kl: 1.33256)
epoch 9
batches 0, loss 34.8045 (re: 68.2105, kl: 1.39853)
batches 100, loss 37.0311 (re: 72.5973, kl: 1.4649)
batches 200, loss 36.2847 (re: 71.1889, kl: 1.38051)
batches 300, loss 37.7234 (re: 74.0767, kl: 1.37004)
batches 400, loss 34.8352 (re: 68.2695, kl: 1.40092)
batches 500, loss 34.6947 (re: 68.1412, kl: 1.24817)
batches 600, loss 36.9714 (re: 72.6034, kl: 1.33933)
batches 700, loss 35.8531 (re: 70.3356, kl: 1.3706)
batches 800, loss 37.4555 (re: 73.5357, kl: 1.37535)
batches 900, loss 36.5847 (re: 71.8494, kl: 1.32002)
epoch 10
batches 0, loss 35.9377 (re: 70.5333, kl: 1.34209)
batches 100, loss 35.5854 (re: 69.941, kl: 1.22983)
batches 200, loss 35.3826 (re: 69.4377, kl: 1.32752)
batches 300, loss 35.1919 (re: 69.091, kl: 1.29279)
batches 400, loss 33.8194 (re: 66.3375, kl: 1.30137)
batches 500, loss 35.0107 (re: 68.7475, kl: 1.2739)
batches 600, loss 35.2499 (re: 69.2572, kl: 1.24259)
batches 700, loss 34.4827 (re: 67.712, kl: 1.25344)
batches 800, loss 36.6256 (re: 71.9583, kl: 1.29294)
batches 900, loss 33.6908 (re: 66.1394, kl: 1.24208)
epoch 11
batches 0, loss 34.8917 (re: 68.5902, kl: 1.19317)
batches 100, loss 35.8568 (re: 70.442, kl: 1.27157)
batches 200, loss 34.8481 (re: 68.6096, kl: 1.08652)
batches 300, loss 32.6104 (re: 64.0383, kl: 1.1825)
batches 400, loss 34.2808 (re: 67.3512, kl: 1.21048)
batches 500, loss 35.2451 (re: 69.2859, kl: 1.20435)
batches 600, loss 33.286 (re: 65.3753, kl: 1.19675)
batches 700, loss 32.9224 (re: 64.7847, kl: 1.0601)
batches 800, loss 32.9984 (re: 64.8923, kl: 1.10449)
batches 900, loss 34.7642 (re: 68.4195, kl: 1.10894)
epoch 12
batches 0, loss 32.2821 (re: 63.4944, kl: 1.06981)
batches 100, loss 34.3077 (re: 67.5066, kl: 1.10882)
batches 200, loss 33.4409 (re: 65.7593, kl: 1.12256)
batches 300, loss 33.3524 (re: 65.5791, kl: 1.12579)
batches 400, loss 32.4175 (re: 63.6251, kl: 1.20985)
batches 500, loss 34.2778 (re: 67.4367, kl: 1.11878)
batches 600, loss 31.7433 (re: 62.3913, kl: 1.09535)
batches 700, loss 33.0884 (re: 65.0655, kl: 1.11129)
batches 800, loss 33.2725 (re: 65.428, kl: 1.11705)
batches 900, loss 32.4279 (re: 63.7636, kl: 1.09213)
epoch 13
batches 0, loss 32.0056 (re: 63.0407, kl: 0.970515)
batches 100, loss 32.7493 (re: 64.4536, kl: 1.04507)
batches 200, loss 34.5395 (re: 67.9877, kl: 1.0912)
batches 300, loss 33.6683 (re: 66.2547, kl: 1.08195)
batches 400, loss 34.3967 (re: 67.6367, kl: 1.15665)
batches 500, loss 33.0002 (re: 64.9619, kl: 1.03851)
batches 600, loss 32.7057 (re: 64.3682, kl: 1.04315)
batches 700, loss 33.2304 (re: 65.4551, kl: 1.00576)
batches 800, loss 34.0253 (re: 66.9719, kl: 1.07873)
batches 900, loss 33.2729 (re: 65.5277, kl: 1.01821)
epoch 14
batches 0, loss 32.7977 (re: 64.5599, kl: 1.03558)
batches 100, loss 33.6539 (re: 66.2347, kl: 1.07313)
batches 200, loss 34.4469 (re: 67.898, kl: 0.995804)
batches 300, loss 32.315 (re: 63.5858, kl: 1.04433)
batches 400, loss 31.0486 (re: 61.0838, kl: 1.0134)
batches 500, loss 33.4328 (re: 65.8996, kl: 0.965914)
batches 600, loss 32.9166 (re: 64.8601, kl: 0.973145)
batches 700, loss 32.4507 (re: 63.8913, kl: 1.00998)
batches 800, loss 33.0318 (re: 65.078, kl: 0.985577)
batches 900, loss 32.1381 (re: 63.3476, kl: 0.928594)
epoch 15
batches 0, loss 31.8464 (re: 62.6758, kl: 1.01697)
batches 100, loss 31.0563 (re: 61.1881, kl: 0.924538)
batches 200, loss 31.556 (re: 62.1771, kl: 0.935003)
batches 300, loss 31.7698 (re: 62.555, kl: 0.984586)
batches 400, loss 32.0069 (re: 63.0965, kl: 0.917265)
batches 500, loss 31.2204 (re: 61.4937, kl: 0.947026)
batches 600, loss 33.4872 (re: 66.0067, kl: 0.967679)
batches 700, loss 31.9301 (re: 62.9661, kl: 0.894057)
batches 800, loss 32.7073 (re: 64.5128, kl: 0.901689)
batches 900, loss 32.1101 (re: 63.341, kl: 0.879335)
epoch 16
batches 0, loss 31.8873 (re: 62.8252, kl: 0.949313)
batches 100, loss 30.9705 (re: 61.0643, kl: 0.876628)
batches 200, loss 32.3973 (re: 63.8687, kl: 0.925949)
batches 300, loss 32.1712 (re: 63.3608, kl: 0.981638)
batches 400, loss 31.5898 (re: 62.3239, kl: 0.855752)
batches 500, loss 32.1844 (re: 63.4169, kl: 0.951791)
batches 600, loss 33.1453 (re: 65.3455, kl: 0.945195)
batches 700, loss 30.8729 (re: 60.8458, kl: 0.899892)
batches 800, loss 31.2186 (re: 61.5513, kl: 0.885841)
batches 900, loss 30.2151 (re: 59.5193, kl: 0.91086)
epoch 17
batches 0, loss 31.6896 (re: 62.4978, kl: 0.881452)
batches 100, loss 30.9811 (re: 61.1353, kl: 0.826855)
batches 200, loss 32.298 (re: 63.6676, kl: 0.928338)
batches 300, loss 31.9487 (re: 63.019, kl: 0.8785)
batches 400, loss 31.0574 (re: 61.2856, kl: 0.829138)
batches 500, loss 30.4439 (re: 60.0313, kl: 0.856445)
batches 600, loss 31.0397 (re: 61.2421, kl: 0.837283)
batches 700, loss 33.0733 (re: 65.2305, kl: 0.916195)
batches 800, loss 31.6649 (re: 62.4875, kl: 0.842242)
batches 900, loss 30.9253 (re: 61.0565, kl: 0.794054)
epoch 18
batches 0, loss 31.0499 (re: 61.3044, kl: 0.795419)
batches 100, loss 29.5954 (re: 58.4011, kl: 0.78964)
batches 200, loss 30.7634 (re: 60.6437, kl: 0.883081)
batches 300, loss 29.3386 (re: 57.8872, kl: 0.789965)
batches 400, loss 31.0431 (re: 61.2768, kl: 0.809381)
batches 500, loss 30.8345 (re: 60.8026, kl: 0.866418)
batches 600, loss 32.1085 (re: 63.3828, kl: 0.83419)
batches 700, loss 31.0054 (re: 61.2269, kl: 0.783895)
batches 800, loss 30.8838 (re: 60.947, kl: 0.82059)
batches 900, loss 32.0921 (re: 63.3514, kl: 0.832819)
epoch 19
batches 0, loss 30.9829 (re: 61.1711, kl: 0.794635)
batches 100, loss 30.3599 (re: 59.9127, kl: 0.807213)
batches 200, loss 31.8002 (re: 62.7815, kl: 0.818834)
batches 300, loss 31.6445 (re: 62.4631, kl: 0.82592)
batches 400, loss 30.8773 (re: 60.9538, kl: 0.800812)
batches 500, loss 30.8663 (re: 60.9572, kl: 0.775409)
batches 600, loss 30.2512 (re: 59.7521, kl: 0.75035)
batches 700, loss 32.3986 (re: 63.9813, kl: 0.815858)
batches 800, loss 30.5137 (re: 60.2333, kl: 0.794053)
batches 900, loss 30.4662 (re: 60.0936, kl: 0.838814)

